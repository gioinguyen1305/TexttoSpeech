{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c612760-9a51-4bbc-a574-454ed9bac6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch  # isort:skip\n",
    "torch.manual_seed(42)\n",
    "import json\n",
    "import re\n",
    "import unicodedata\n",
    "from types import SimpleNamespace\n",
    "import gradio as gr\n",
    "import numpy as np\n",
    "import regex\n",
    "from models import DurationNet, SynthesizerTrn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "922692fc-ba0f-49e5-959e-8f0eaffd50ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"LightSpeed: Vietnamese Female Voice TTS\"\n",
    "description = \"Vietnam Female Voice TTS.\"\n",
    "config_file = \"config.json\"\n",
    "duration_model_path = \"duration_model.pth\"\n",
    "lightspeed_model_path = \"gen_630k.pth\"\n",
    "phone_set_file = \"phone_set.json\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c480aec3-450a-4cf0-969b-7c9901a55a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(config_file, \"rb\") as f:\n",
    "    hps = json.load(f, object_hook=lambda x: SimpleNamespace(**x))\n",
    "\n",
    "# load phone set json file\n",
    "with open(phone_set_file, \"r\") as f:\n",
    "    phone_set = json.load(f)\n",
    "\n",
    "assert phone_set[0][1:-1] == \"SEP\"\n",
    "assert \"sil\" in phone_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e901f465-d5cf-406f-b6ed-250124c59f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_idx = phone_set.index(\"sil\")\n",
    "space_re = regex.compile(r\"\\s+\")\n",
    "number_re = regex.compile(\"([0-9]+)\")\n",
    "digits = [\"không\", \"một\", \"hai\", \"ba\", \"bốn\", \"năm\", \"sáu\", \"bảy\", \"tám\", \"chín\"]\n",
    "num_re = regex.compile(r\"([0-9.,]*[0-9])\")\n",
    "alphabet = \"aàáảãạăằắẳẵặâầấẩẫậeèéẻẽẹêềếểễệiìíỉĩịoòóỏõọôồốổỗộơờớởỡợuùúủũụưừứửữựyỳýỷỹỵbcdđghklmnpqrstvx\"\n",
    "keep_text_and_num_re = regex.compile(rf\"[^\\s{alphabet}.,0-9]\")\n",
    "keep_text_re = regex.compile(rf\"[^\\s{alphabet}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf42f516-cf0d-44fe-ad49-cd6a16a5bff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_number(num: str) -> str:\n",
    "    if len(num) == 1:\n",
    "        return digits[int(num)]\n",
    "    elif len(num) == 2 and num.isdigit():\n",
    "        n = int(num)\n",
    "        end = digits[n % 10]\n",
    "        if n == 10:\n",
    "            return \"mười\"\n",
    "        if n % 10 == 5:\n",
    "            end = \"lăm\"\n",
    "        if n % 10 == 0:\n",
    "            return digits[n // 10] + \" mươi\"\n",
    "        elif n < 20:\n",
    "            return \"mười \" + end\n",
    "        else:\n",
    "            if n % 10 == 1:\n",
    "                end = \"mốt\"\n",
    "            return digits[n // 10] + \" mươi \" + end\n",
    "    elif len(num) == 3 and num.isdigit():\n",
    "        n = int(num)\n",
    "        if n % 100 == 0:\n",
    "            return digits[n // 100] + \" trăm\"\n",
    "        elif num[1] == \"0\":\n",
    "            return digits[n // 100] + \" trăm lẻ \" + digits[n % 100]\n",
    "        else:\n",
    "            return digits[n // 100] + \" trăm \" + read_number(num[1:])\n",
    "    elif len(num) >= 4 and len(num) <= 6 and num.isdigit():\n",
    "        n = int(num)\n",
    "        n1 = n // 1000\n",
    "        return read_number(str(n1)) + \" ngàn \" + read_number(num[-3:])\n",
    "    elif \",\" in num:\n",
    "        n1, n2 = num.split(\",\")\n",
    "        return read_number(n1) + \" phẩy \" + read_number(n2)\n",
    "    elif \".\" in num:\n",
    "        parts = num.split(\".\")\n",
    "        if len(parts) == 2:\n",
    "            if parts[1] == \"000\":\n",
    "                return read_number(parts[0]) + \" ngàn\"\n",
    "            elif parts[1].startswith(\"00\"):\n",
    "                end = digits[int(parts[1][2:])]\n",
    "                return read_number(parts[0]) + \" ngàn lẻ \" + end\n",
    "            else:\n",
    "                return read_number(parts[0]) + \" ngàn \" + read_number(parts[1])\n",
    "        elif len(parts) == 3:\n",
    "            return (\n",
    "                read_number(parts[0])\n",
    "                + \" triệu \"\n",
    "                + read_number(parts[1])\n",
    "                + \" ngàn \"\n",
    "                + read_number(parts[2])\n",
    "            )\n",
    "    return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9508c6c-a792-4026-b672-84ef833ab18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_phone_idx(text):\n",
    "    # lowercase\n",
    "    text = text.lower()\n",
    "    # unicode normalize\n",
    "    text = unicodedata.normalize(\"NFKC\", text)\n",
    "    text = text.replace(\".\", \" . \")\n",
    "    text = text.replace(\",\", \" , \")\n",
    "    text = text.replace(\";\", \" ; \")\n",
    "    text = text.replace(\":\", \" : \")\n",
    "    text = text.replace(\"!\", \" ! \")\n",
    "    text = text.replace(\"?\", \" ? \")\n",
    "    text = text.replace(\"(\", \" ( \")\n",
    "\n",
    "    text = num_re.sub(r\" \\1 \", text)\n",
    "    words = text.split()\n",
    "    words = [read_number(w) if num_re.fullmatch(w) else w for w in words]\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    # remove redundant spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    # remove leading and trailing spaces\n",
    "    text = text.strip()\n",
    "    # convert words to phone indices\n",
    "    tokens = []\n",
    "    for c in text:\n",
    "        # if c is \",\" or \".\", add <sil> phone\n",
    "        if c in \":,.!?;(\":\n",
    "            tokens.append(sil_idx)\n",
    "        elif c in phone_set:\n",
    "            tokens.append(phone_set.index(c))\n",
    "        elif c == \" \":\n",
    "            # add <sep> phone\n",
    "            tokens.append(0)\n",
    "    if tokens[0] != sil_idx:\n",
    "        # insert <sil> phone at the beginning\n",
    "        tokens = [sil_idx, 0] + tokens\n",
    "    if tokens[-1] != sil_idx:\n",
    "        tokens = tokens + [0, sil_idx]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c33fac8c-0f03-43fd-a54e-b92f072909ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_speech(duration_net, generator, text):\n",
    "    # prevent too long text\n",
    "    if len(text) > 500:\n",
    "        text = text[:500]\n",
    "\n",
    "    phone_idx = text_to_phone_idx(text)\n",
    "    batch = {\n",
    "        \"phone_idx\": np.array([phone_idx]),\n",
    "        \"phone_length\": np.array([len(phone_idx)]),\n",
    "    }\n",
    "\n",
    "    # predict phoneme duration\n",
    "    phone_length = torch.from_numpy(batch[\"phone_length\"].copy()).long().to(device)\n",
    "    phone_idx = torch.from_numpy(batch[\"phone_idx\"].copy()).long().to(device)\n",
    "    with torch.inference_mode():\n",
    "        phone_duration = duration_net(phone_idx, phone_length)[:, :, 0] * 1000\n",
    "    phone_duration = torch.where(\n",
    "        phone_idx == sil_idx, torch.clamp_min(phone_duration, 200), phone_duration\n",
    "    )\n",
    "    phone_duration = phone_duration.to(torch.long)\n",
    "    phone_duration = torch.where(phone_idx == 0, 0, phone_duration)\n",
    "\n",
    "    # generate waveform\n",
    "    end_time = torch.cumsum(phone_duration, dim=-1)\n",
    "    start_time = end_time - phone_duration\n",
    "    start_frame = start_time / 1000 * hps.data.sampling_rate / hps.data.hop_length\n",
    "    end_frame = end_time / 1000 * hps.data.sampling_rate / hps.data.hop_length\n",
    "    spec_length = end_frame.max(dim=-1).values\n",
    "    pos = torch.arange(0, spec_length.item(), device=device)\n",
    "    attn = torch.logical_and(\n",
    "        pos[None, :, None] >= start_frame[:, None, :],\n",
    "        pos[None, :, None] < end_frame[:, None, :],\n",
    "    ).float()\n",
    "    with torch.inference_mode():\n",
    "        y_hat = generator.infer(\n",
    "            phone_idx, phone_length, spec_length, attn, max_len=None, noise_scale=0.0\n",
    "        )[0]\n",
    "    wave = y_hat[0, 0].data.cpu().numpy()\n",
    "    return (wave * (2**15)).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d5896c93-b475-499e-8e71-4355de151778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_models():\n",
    "    duration_net = DurationNet(hps.data.vocab_size, 64, 4).to(device)\n",
    "    duration_net.load_state_dict(torch.load(duration_model_path, map_location=device))\n",
    "    duration_net = duration_net.eval()\n",
    "    generator = SynthesizerTrn(\n",
    "        hps.data.vocab_size,\n",
    "        hps.data.filter_length // 2 + 1,\n",
    "        hps.train.segment_size // hps.data.hop_length,\n",
    "        **vars(hps.model),\n",
    "    ).to(device)\n",
    "    del generator.enc_q\n",
    "    ckpt = torch.load(lightspeed_model_path, map_location=device)\n",
    "    params = {}\n",
    "    for k, v in ckpt[\"net_g\"].items():\n",
    "        k = k[7:] if k.startswith(\"module.\") else k\n",
    "        params[k] = v\n",
    "    generator.load_state_dict(params, strict=False)\n",
    "    del ckpt, params\n",
    "    generator = generator.eval()\n",
    "    return duration_net, generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cfe14aac-54ff-4dd8-b926-99e99770898e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(text):\n",
    "    duration_net, generator = load_models()\n",
    "    paragraphs = text.split(\"\\n\")\n",
    "    clips = []  # list of audio clips\n",
    "    # silence = np.zeros(hps.data.sampling_rate // 4)\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph = paragraph.strip()\n",
    "        if paragraph == \"\":\n",
    "            continue\n",
    "        clips.append(text_to_speech(duration_net, generator, paragraph))\n",
    "        # clips.append(silence)\n",
    "    y = np.concatenate(clips)\n",
    "    return hps.data.sampling_rate, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3e8b07-9f4d-420b-acdf-034712d078af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec446b88-36e9-49b4-a6f4-6f9f4f908012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e17e50-6951-42ec-9ce3-7a108e96c0c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa30096-6ba9-482f-be4e-a7c7c3bb5291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ac11a99-77d5-4a7f-94a0-7514829c2704",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d765427f-73de-4ec4-8477-3d4d9b57e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    fn=speak,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"audio\",\n",
    "    title=title,\n",
    "    examples=[\n",
    "        \"Trăm năm trong cõi người ta, chữ tài chữ mệnh khéo là ghét nhau.\",\n",
    "        \"Đoạn trường tân thanh, thường được biết đến với cái tên đơn giản là Truyện Kiều, là một truyện thơ của đại thi hào Nguyễn Du\",\n",
    "        \"Lục Vân Tiên quê ở huyện Đông Thành, khôi ngô tuấn tú, tài kiêm văn võ. Nghe tin triều đình mở khoa thi, Vân Tiên từ giã thầy xuống núi đua tài.\",\n",
    "        \"Lê Quý Đôn, tên thuở nhỏ là Lê Danh Phương, là vị quan thời Lê trung hưng, cũng là nhà thơ và được mệnh danh là nhà bác học lớn của Việt Nam trong thời phong kiến\",\n",
    "        \"Tất cả mọi người đều sinh ra có quyền bình đẳng. Tạo hóa cho họ những quyền không ai có thể xâm phạm được; trong những quyền ấy, có quyền được sống, quyền tự do và quyền mưu cầu hạnh phúc.\",\n",
    "    ],\n",
    "    description=description,\n",
    "    theme=\"default\",\n",
    "    allow_flagging=\"never\",\n",
    ").launch(debug=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bf33a76-76b4-4ae1-8993-648ebb9876b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
